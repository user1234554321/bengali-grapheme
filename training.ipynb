{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "bengali-grapheme.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CtdMP1QFHjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /root/.kaggle\n",
        "!cp kaggle.json /root/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkmdvqP5FHbh",
        "colab_type": "code",
        "outputId": "f72497a7-002f-4fb9-a09f-4a76363f06e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "!kaggle competitions download -c bengaliai-cv19"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading class_map.csv to /content\n",
            "\r  0% 0.00/4.72k [00:00<?, ?B/s]\n",
            "100% 4.72k/4.72k [00:00<00:00, 15.0MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "  0% 0.00/1.32M [00:00<?, ?B/s]\n",
            "100% 1.32M/1.32M [00:00<00:00, 90.1MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/1.70k [00:00<?, ?B/s]\n",
            "100% 1.70k/1.70k [00:00<00:00, 1.74MB/s]\n",
            "Downloading train_image_data_2.parquet.zip to /content\n",
            " 99% 978M/992M [00:14<00:00, 34.6MB/s]\n",
            "100% 992M/992M [00:14<00:00, 72.4MB/s]\n",
            "Downloading train_image_data_0.parquet.zip to /content\n",
            " 98% 968M/991M [00:11<00:00, 36.8MB/s]\n",
            "100% 991M/991M [00:11<00:00, 92.2MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/944 [00:00<?, ?B/s]\n",
            "100% 944/944 [00:00<00:00, 827kB/s]\n",
            "Downloading train_image_data_1.parquet.zip to /content\n",
            " 99% 980M/986M [00:21<00:00, 109MB/s] \n",
            "100% 986M/986M [00:21<00:00, 48.5MB/s]\n",
            "Downloading test_image_data_1.parquet.zip to /content\n",
            "  0% 0.00/1.30M [00:00<?, ?B/s]\n",
            "100% 1.30M/1.30M [00:00<00:00, 172MB/s]\n",
            "Downloading train_image_data_3.parquet.zip to /content\n",
            " 99% 985M/993M [00:25<00:00, 17.9MB/s]\n",
            "100% 993M/993M [00:25<00:00, 40.6MB/s]\n",
            "Downloading test_image_data_3.parquet.zip to /content\n",
            "  0% 0.00/1.28M [00:00<?, ?B/s]\n",
            "100% 1.28M/1.28M [00:00<00:00, 149MB/s]\n",
            "Downloading test_image_data_0.parquet.zip to /content\n",
            "  0% 0.00/1.18M [00:00<?, ?B/s]\n",
            "100% 1.18M/1.18M [00:00<00:00, 80.0MB/s]\n",
            "Downloading test_image_data_2.parquet.zip to /content\n",
            "  0% 0.00/1.25M [00:00<?, ?B/s]\n",
            "100% 1.25M/1.25M [00:00<00:00, 182MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNXjCqhCFLBp",
        "colab_type": "code",
        "outputId": "13cc3323-4398-42b7-81f3-65c601107e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "!unzip test_image_data_0.parquet.zip\n",
        "!unzip test_image_data_1.parquet.zip\n",
        "!unzip test_image_data_2.parquet.zip\n",
        "!unzip test_image_data_3.parquet.zip\n",
        "!unzip train_image_data_0.parquet.zip\n",
        "!unzip train_image_data_1.parquet.zip\n",
        "!unzip train_image_data_2.parquet.zip\n",
        "!unzip train_image_data_3.parquet.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test_image_data_0.parquet.zip\n",
            "  inflating: test_image_data_0.parquet  \n",
            "Archive:  test_image_data_1.parquet.zip\n",
            "  inflating: test_image_data_1.parquet  \n",
            "Archive:  test_image_data_2.parquet.zip\n",
            "  inflating: test_image_data_2.parquet  \n",
            "Archive:  test_image_data_3.parquet.zip\n",
            "  inflating: test_image_data_3.parquet  \n",
            "Archive:  train_image_data_0.parquet.zip\n",
            "  inflating: train_image_data_0.parquet  \n",
            "Archive:  train_image_data_1.parquet.zip\n",
            "  inflating: train_image_data_1.parquet  \n",
            "Archive:  train_image_data_2.parquet.zip\n",
            "  inflating: train_image_data_2.parquet  \n",
            "Archive:  train_image_data_3.parquet.zip\n",
            "  inflating: train_image_data_3.parquet  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaaa4LRKFK7o",
        "colab_type": "code",
        "outputId": "51c3dfe7-9faa-47c3-f204-9c1da23dd9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip train.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jYwKrSR3ybS4",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EvyMoIPYy3Gw",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "submission_df = pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bP4GTGl90JIk",
        "outputId": "5c6ca3a5-9613-4752-c290-599f6f4d121b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>grapheme_root</th>\n",
              "      <th>vowel_diacritic</th>\n",
              "      <th>consonant_diacritic</th>\n",
              "      <th>grapheme</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train_0</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>ক্ট্রো</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Train_1</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>হ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Train_2</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>খ্রী</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Train_3</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>র্টি</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Train_4</td>\n",
              "      <td>71</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>থ্রো</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
              "0  Train_0             15                9                    5   ক্ট্রো\n",
              "1  Train_1            159                0                    0        হ\n",
              "2  Train_2             22                3                    5     খ্রী\n",
              "3  Train_3             53                2                    2     র্টি\n",
              "4  Train_4             71                9                    5     থ্রো"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DxQ2_CWF0Ldx",
        "outputId": "1d77b168-96a8-48b9-f959-545333e4facd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_df.grapheme_root.unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j0tFl0FbH09r",
        "outputId": "d9add206-fc76-4302-b1ae-c5c81399093f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_df.vowel_diacritic.unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zJTNffkeH01l",
        "outputId": "f1bed7ee-970e-4561-9750-9a516390073d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_df.consonant_diacritic.unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OQLhHXuv0WdR",
        "colab": {}
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NYv_6oOp1Zn1",
        "colab": {}
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, labels, train_images, image_ids, transforms=None):\n",
        "        super(Dataset, self).__init__()\n",
        "        self.image_ids = image_ids\n",
        "        self.train_images = train_images\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_id = self.image_ids.iloc[index]\n",
        "        img_array = np.zeros((137, 236, 3), dtype='uint8')\n",
        "        img_array[:, :, 0] = 255 - self.train_images[index].reshape(137, 236)\n",
        "        img_array[:, :, 1] = img_array[:, :, 0]\n",
        "        img_array[:, :, 2] = img_array[:, :, 0]\n",
        "        img = Image.fromarray(img_array)\n",
        "        grapheme_root = self.labels[index, 1]\n",
        "        vowel_diacritic = self.labels[index, 2]\n",
        "        consonant_diacritic = self.labels[index, 3]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, (grapheme_root, vowel_diacritic, consonant_diacritic)\n",
        "\n",
        "    def __len__(self,):\n",
        "        return len(self.image_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kGFe6u1HFAtc",
        "colab": {}
      },
      "source": [
        "class GraphemeModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GraphemeModel, self).__init__()\n",
        "        self.base_model = torchvision.models.resnet50(pretrained=False)\n",
        "        # self.fc = nn.Linear(1000, 256)\n",
        "        self.fc_root = nn.Linear(1000, 168)\n",
        "        self.fc_vowel = nn.Linear(1000, 11)\n",
        "        self.fc_consonant = nn.Linear(1000, 7)\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        x = self.base_model(inp)\n",
        "        # x = x.view(x.shape[0], -1)\n",
        "        # x = F.relu(self.fc(x))\n",
        "        root_output = self.fc_root(x)\n",
        "        vowel_output = self.fc_vowel(x)\n",
        "        consonant_output = self.fc_consonant(x)\n",
        "\n",
        "        return (root_output, vowel_output, consonant_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eobPyPaGyKLO",
        "colab": {}
      },
      "source": [
        "train_image_data_0 = pd.read_parquet('train_image_data_0.parquet', engine='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HvA1Uu2FErS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_data_1 = pd.read_parquet('train_image_data_1.parquet', engine='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHCGHti-FErV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_data_2 = pd.read_parquet('train_image_data_2.parquet', engine='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fLG3c4pFErX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_data_3 = pd.read_parquet('train_image_data_3.parquet', engine='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzI-Un7lFErZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_matrix = np.concatenate([\n",
        "                    train_image_data_0.drop(columns=['image_id']).values,\n",
        "                    train_image_data_1.drop(columns=['image_id']).values,\n",
        "                    train_image_data_2.drop(columns=['image_id']).values,\n",
        "                ])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HfuLRuIVJQL4",
        "colab": {}
      },
      "source": [
        "transforms = torchvision.transforms.Compose([\n",
        "                              # torchvision.transforms.Resize((224, 224)),\n",
        "                              torchvision.transforms.RandomAffine(degrees=0, scale=(0.9, 1.1), translate=(0.1, 0.1)),\n",
        "                              torchvision.transforms.ToTensor(),\n",
        "                              torchvision.transforms.Normalize((0,), (1.,)),\n",
        "\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbP9KyqRXRri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms1 = torchvision.transforms.Compose([\n",
        "                              # torchvision.transforms.Resize((224, 224)),\n",
        "                              # torchvision.transforms.RandomRotation(degrees=20),\n",
        "                              # torchvision.transforms.RandomPerspective(),\n",
        "                              torchvision.transforms.ToTensor(),\n",
        "                              torchvision.transforms.Normalize((0,), (1.,)),\n",
        "\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xe2lx1ThRAd6",
        "colab": {}
      },
      "source": [
        "val_matrix = train_image_data_3.drop(columns=['image_id']).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UPRrn8vvQ2Gw",
        "colab": {}
      },
      "source": [
        "val_dataset = Dataset(labels=train_df.iloc[50210*3:50210*4].values, train_images=val_matrix, image_ids=train_image_data_3.image_id, transforms=transforms1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8SRaLWMDREHA",
        "colab": {}
      },
      "source": [
        "val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSilkhOsFErk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_ids = train_image_data_0.image_id.append(train_image_data_1.image_id).append(train_image_data_2.image_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ikH-whuaH_-3",
        "colab": {}
      },
      "source": [
        "train_dataset = Dataset(labels=train_df.iloc[:50210*3].values, train_images=train_matrix, image_ids=image_ids, transforms=transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HcWGhf6GImYE",
        "colab": {}
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JEma5xfbItv0",
        "colab": {}
      },
      "source": [
        "model = GraphemeModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uoRAmukKy3nt",
        "colab": {}
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W6Ygw355N7yC",
        "colab": {}
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aXhn6QaIIyeO",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rr7Nulx-I_f7",
        "colab": {}
      },
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yzP12QS2Ci_P",
        "colab": {}
      },
      "source": [
        "def accuracy(y_actual, y_pred):\n",
        "    return (y_actual == y_pred).sum().item() / y_actual.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPwc_LGg7NEJ",
        "colab_type": "code",
        "outputId": "78c422dc-e99d-4605-c300-88451372c94c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "t(img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAACJCAIAAACgiEOqAAA6pElEQVR4nO192VccR5Z+ZNa+b1RB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\nA4gRNB4DbXTPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=236x137 at 0x7FB6158039E8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uBzJyfUEJD0L",
        "outputId": "30630489-5ae8-4b53-b769-7c51e3ed0370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.train()\n",
        "model.base_model.train()\n",
        "for epoch in range(3):\n",
        "    for x, (root, vowel, consonant) in train_dataloader:\n",
        "        opt.zero_grad()\n",
        "        output = model(x.to(device))\n",
        "        loss_root = criterion(output[0], root.to(device))\n",
        "        loss_vowel = criterion(output[1], vowel.to(device))\n",
        "        loss_consonant = criterion(output[2], consonant.to(device))\n",
        "        loss = loss_root * 2 + loss_vowel + loss_consonant\n",
        "        loss.backward()\n",
        "        print('Accuracy: ', accuracy(root, output[0].detach().cpu().argmax(1)), end=', ')\n",
        "        # loss_root.backward()\n",
        "        opt.step()\n",
        "        print('Loss: ', loss.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9375, Loss:  0.668513298034668\n",
            "Accuracy:  0.953125, Loss:  0.3417900800704956\n",
            "Accuracy:  0.96875, Loss:  0.23682381212711334\n",
            "Accuracy:  0.984375, Loss:  0.3091973662376404\n",
            "Accuracy:  0.984375, Loss:  0.4172873795032501\n",
            "Accuracy:  0.90625, Loss:  0.7336642742156982\n",
            "Accuracy:  0.9375, Loss:  0.5209102630615234\n",
            "Accuracy:  0.90625, Loss:  0.5056759715080261\n",
            "Accuracy:  0.921875, Loss:  0.5816317200660706\n",
            "Accuracy:  0.984375, Loss:  0.17625820636749268\n",
            "Accuracy:  0.890625, Loss:  0.821493923664093\n",
            "Accuracy:  0.921875, Loss:  0.7236595749855042\n",
            "Accuracy:  0.984375, Loss:  0.5171566009521484\n",
            "Accuracy:  0.96875, Loss:  0.27135348320007324\n",
            "Accuracy:  0.96875, Loss:  0.3923593759536743\n",
            "Accuracy:  0.953125, Loss:  0.6037377715110779\n",
            "Accuracy:  0.96875, Loss:  0.396128386259079\n",
            "Accuracy:  0.9375, Loss:  0.8164109587669373\n",
            "Accuracy:  0.953125, Loss:  0.4914555549621582\n",
            "Accuracy:  0.953125, Loss:  0.3907659351825714\n",
            "Accuracy:  0.9375, Loss:  0.4809139370918274\n",
            "Accuracy:  0.953125, Loss:  0.24467319250106812\n",
            "Accuracy:  0.953125, Loss:  0.6239598393440247\n",
            "Accuracy:  0.9375, Loss:  0.7024892568588257\n",
            "Accuracy:  0.96875, Loss:  0.4498065114021301\n",
            "Accuracy:  0.9375, Loss:  0.39626291394233704\n",
            "Accuracy:  0.953125, Loss:  0.48089948296546936\n",
            "Accuracy:  0.9375, Loss:  0.6958238482475281\n",
            "Accuracy:  0.90625, Loss:  0.6978211998939514\n",
            "Accuracy:  0.9375, Loss:  0.4886396527290344\n",
            "Accuracy:  0.96875, Loss:  0.3061966896057129\n",
            "Accuracy:  0.96875, Loss:  0.4518566429615021\n",
            "Accuracy:  0.921875, Loss:  0.7829097509384155\n",
            "Accuracy:  0.96875, Loss:  0.40273815393447876\n",
            "Accuracy:  0.96875, Loss:  0.3431054651737213\n",
            "Accuracy:  0.96875, Loss:  0.38281524181365967\n",
            "Accuracy:  0.96875, Loss:  0.33668798208236694\n",
            "Accuracy:  0.96875, Loss:  0.21064960956573486\n",
            "Accuracy:  0.96875, Loss:  0.28797248005867004\n",
            "Accuracy:  0.953125, Loss:  0.42330849170684814\n",
            "Accuracy:  0.96875, Loss:  0.3181304633617401\n",
            "Accuracy:  0.921875, Loss:  0.6432571411132812\n",
            "Accuracy:  0.96875, Loss:  0.6923345923423767\n",
            "Accuracy:  0.96875, Loss:  0.3429938852787018\n",
            "Accuracy:  0.9375, Loss:  0.39519521594047546\n",
            "Accuracy:  0.953125, Loss:  0.24306952953338623\n",
            "Accuracy:  0.984375, Loss:  0.37772029638290405\n",
            "Accuracy:  0.984375, Loss:  0.2756527364253998\n",
            "Accuracy:  0.9375, Loss:  0.47372281551361084\n",
            "Accuracy:  0.90625, Loss:  0.5625395178794861\n",
            "Accuracy:  0.90625, Loss:  0.6408209800720215\n",
            "Accuracy:  0.953125, Loss:  0.34020692110061646\n",
            "Accuracy:  0.953125, Loss:  0.39403876662254333\n",
            "Accuracy:  0.90625, Loss:  0.5330398082733154\n",
            "Accuracy:  0.96875, Loss:  0.24016010761260986\n",
            "Accuracy:  0.96875, Loss:  0.3055509924888611\n",
            "Accuracy:  0.953125, Loss:  0.5233322978019714\n",
            "Accuracy:  0.84375, Loss:  0.9340319037437439\n",
            "Accuracy:  0.890625, Loss:  0.8297237753868103\n",
            "Accuracy:  0.953125, Loss:  0.4920647442340851\n",
            "Accuracy:  0.9375, Loss:  0.34108927845954895\n",
            "Accuracy:  0.9375, Loss:  0.6503185629844666\n",
            "Accuracy:  0.984375, Loss:  0.3322262763977051\n",
            "Accuracy:  0.96875, Loss:  0.27007579803466797\n",
            "Accuracy:  0.953125, Loss:  0.5059443712234497\n",
            "Accuracy:  0.984375, Loss:  0.23559537529945374\n",
            "Accuracy:  0.953125, Loss:  0.4986036419868469\n",
            "Accuracy:  0.96875, Loss:  0.4422820806503296\n",
            "Accuracy:  0.953125, Loss:  0.34080713987350464\n",
            "Accuracy:  0.9375, Loss:  0.508980929851532\n",
            "Accuracy:  1.0, Loss:  0.20753301680088043\n",
            "Accuracy:  0.96875, Loss:  0.48521649837493896\n",
            "Accuracy:  0.984375, Loss:  0.2138335257768631\n",
            "Accuracy:  0.96875, Loss:  0.16900873184204102\n",
            "Accuracy:  0.953125, Loss:  0.5659419298171997\n",
            "Accuracy:  0.953125, Loss:  0.3846035897731781\n",
            "Accuracy:  0.96875, Loss:  0.6459582448005676\n",
            "Accuracy:  0.984375, Loss:  0.26196223497390747\n",
            "Accuracy:  0.921875, Loss:  0.6069464683532715\n",
            "Accuracy:  0.96875, Loss:  0.48410362005233765\n",
            "Accuracy:  0.984375, Loss:  0.4306522011756897\n",
            "Accuracy:  0.9375, Loss:  0.8291653394699097\n",
            "Accuracy:  0.984375, Loss:  0.19028803706169128\n",
            "Accuracy:  0.953125, Loss:  0.2821097671985626\n",
            "Accuracy:  0.96875, Loss:  0.5214436650276184\n",
            "Accuracy:  0.96875, Loss:  0.3082936108112335\n",
            "Accuracy:  0.984375, Loss:  0.20661771297454834\n",
            "Accuracy:  0.953125, Loss:  0.40516626834869385\n",
            "Accuracy:  0.953125, Loss:  0.36230000853538513\n",
            "Accuracy:  0.96875, Loss:  0.21424183249473572\n",
            "Accuracy:  0.953125, Loss:  0.4653800427913666\n",
            "Accuracy:  0.921875, Loss:  0.5451953411102295\n",
            "Accuracy:  0.921875, Loss:  0.43075788021087646\n",
            "Accuracy:  0.890625, Loss:  0.6411571502685547\n",
            "Accuracy:  0.9375, Loss:  0.7259240746498108\n",
            "Accuracy:  0.96875, Loss:  0.3030766248703003\n",
            "Accuracy:  0.90625, Loss:  0.48758357763290405\n",
            "Accuracy:  0.96875, Loss:  0.30978983640670776\n",
            "Accuracy:  0.96875, Loss:  0.3650299310684204\n",
            "Accuracy:  0.96875, Loss:  0.3173290193080902\n",
            "Accuracy:  0.953125, Loss:  0.2473469376564026\n",
            "Accuracy:  0.984375, Loss:  0.4629194438457489\n",
            "Accuracy:  0.921875, Loss:  0.5486421585083008\n",
            "Accuracy:  0.96875, Loss:  0.5692815780639648\n",
            "Accuracy:  0.984375, Loss:  0.20395654439926147\n",
            "Accuracy:  0.953125, Loss:  0.5923418998718262\n",
            "Accuracy:  0.96875, Loss:  0.40628111362457275\n",
            "Accuracy:  0.90625, Loss:  0.6443634629249573\n",
            "Accuracy:  0.921875, Loss:  0.5126173496246338\n",
            "Accuracy:  0.9375, Loss:  0.5404427647590637\n",
            "Accuracy:  0.96875, Loss:  0.3441353142261505\n",
            "Accuracy:  0.9375, Loss:  0.5637858510017395\n",
            "Accuracy:  0.96875, Loss:  0.1830359548330307\n",
            "Accuracy:  0.953125, Loss:  0.4051154851913452\n",
            "Accuracy:  0.96875, Loss:  0.3225244879722595\n",
            "Accuracy:  0.953125, Loss:  0.33272406458854675\n",
            "Accuracy:  0.90625, Loss:  0.5631659030914307\n",
            "Accuracy:  0.90625, Loss:  0.7406296133995056\n",
            "Accuracy:  0.96875, Loss:  0.20563682913780212\n",
            "Accuracy:  0.953125, Loss:  0.4408210217952728\n",
            "Accuracy:  0.921875, Loss:  0.44447168707847595\n",
            "Accuracy:  1.0, Loss:  0.2178289145231247\n",
            "Accuracy:  0.890625, Loss:  0.48367786407470703\n",
            "Accuracy:  0.9375, Loss:  0.45469170808792114\n",
            "Accuracy:  0.953125, Loss:  0.7541970014572144\n",
            "Accuracy:  0.96875, Loss:  0.24164460599422455\n",
            "Accuracy:  0.9375, Loss:  0.35438278317451477\n",
            "Accuracy:  1.0, Loss:  0.10143664479255676\n",
            "Accuracy:  1.0, Loss:  0.23116435110569\n",
            "Accuracy:  0.984375, Loss:  0.34245753288269043\n",
            "Accuracy:  0.921875, Loss:  0.5014020204544067\n",
            "Accuracy:  0.953125, Loss:  0.5832826495170593\n",
            "Accuracy:  0.953125, Loss:  0.3577556610107422\n",
            "Accuracy:  0.921875, Loss:  0.4520777463912964\n",
            "Accuracy:  0.921875, Loss:  0.6593514680862427\n",
            "Accuracy:  0.96875, Loss:  0.36141249537467957\n",
            "Accuracy:  0.9375, Loss:  0.3733017146587372\n",
            "Accuracy:  0.921875, Loss:  0.5327392220497131\n",
            "Accuracy:  0.96875, Loss:  0.2980498671531677\n",
            "Accuracy:  0.9375, Loss:  0.4911139905452728\n",
            "Accuracy:  0.96875, Loss:  0.4159899055957794\n",
            "Accuracy:  0.96875, Loss:  0.20872390270233154\n",
            "Accuracy:  0.984375, Loss:  0.219434916973114\n",
            "Accuracy:  0.984375, Loss:  0.2683553695678711\n",
            "Accuracy:  0.96875, Loss:  0.4038447439670563\n",
            "Accuracy:  0.953125, Loss:  0.6001854538917542\n",
            "Accuracy:  0.953125, Loss:  0.22467926144599915\n",
            "Accuracy:  0.96875, Loss:  0.3893529772758484\n",
            "Accuracy:  0.953125, Loss:  0.4362066686153412\n",
            "Accuracy:  0.96875, Loss:  0.37372735142707825\n",
            "Accuracy:  0.984375, Loss:  0.20283135771751404\n",
            "Accuracy:  0.953125, Loss:  0.5914938449859619\n",
            "Accuracy:  0.984375, Loss:  0.24722465872764587\n",
            "Accuracy:  0.953125, Loss:  0.33146411180496216\n",
            "Accuracy:  1.0, Loss:  0.21878445148468018\n",
            "Accuracy:  0.921875, Loss:  0.664770781993866\n",
            "Accuracy:  0.921875, Loss:  0.5435149073600769\n",
            "Accuracy:  0.921875, Loss:  0.9015918970108032\n",
            "Accuracy:  0.921875, Loss:  0.7036900520324707\n",
            "Accuracy:  0.921875, Loss:  0.42415499687194824\n",
            "Accuracy:  0.921875, Loss:  0.578495442867279\n",
            "Accuracy:  0.953125, Loss:  0.3050715923309326\n",
            "Accuracy:  0.96875, Loss:  0.4740999639034271\n",
            "Accuracy:  0.921875, Loss:  0.5733556151390076\n",
            "Accuracy:  0.921875, Loss:  1.1941664218902588\n",
            "Accuracy:  0.921875, Loss:  0.5031898021697998\n",
            "Accuracy:  0.9375, Loss:  0.7991546392440796\n",
            "Accuracy:  0.921875, Loss:  0.6669192314147949\n",
            "Accuracy:  0.984375, Loss:  0.41214221715927124\n",
            "Accuracy:  0.984375, Loss:  0.2281310111284256\n",
            "Accuracy:  0.90625, Loss:  0.7654967904090881\n",
            "Accuracy:  0.96875, Loss:  0.376742959022522\n",
            "Accuracy:  0.953125, Loss:  0.4501274526119232\n",
            "Accuracy:  0.9375, Loss:  0.4342538118362427\n",
            "Accuracy:  0.953125, Loss:  0.4191133975982666\n",
            "Accuracy:  0.921875, Loss:  0.42846792936325073\n",
            "Accuracy:  1.0, Loss:  0.25821149349212646\n",
            "Accuracy:  0.875, Loss:  0.829218327999115\n",
            "Accuracy:  0.96875, Loss:  0.18929173052310944\n",
            "Accuracy:  0.96875, Loss:  0.2460050880908966\n",
            "Accuracy:  0.9375, Loss:  0.45900121331214905\n",
            "Accuracy:  0.9375, Loss:  0.41123831272125244\n",
            "Accuracy:  0.9375, Loss:  0.663192629814148\n",
            "Accuracy:  0.96875, Loss:  0.355459988117218\n",
            "Accuracy:  0.984375, Loss:  0.2936977744102478\n",
            "Accuracy:  0.953125, Loss:  0.4373842775821686\n",
            "Accuracy:  0.953125, Loss:  0.5031476020812988\n",
            "Accuracy:  0.984375, Loss:  0.1376398652791977\n",
            "Accuracy:  0.953125, Loss:  0.5143027901649475\n",
            "Accuracy:  0.953125, Loss:  0.49400684237480164\n",
            "Accuracy:  0.953125, Loss:  0.22622987627983093\n",
            "Accuracy:  0.9375, Loss:  0.5547273755073547\n",
            "Accuracy:  1.0, Loss:  0.1871168613433838\n",
            "Accuracy:  0.96875, Loss:  0.27533259987831116\n",
            "Accuracy:  0.953125, Loss:  0.4543426036834717\n",
            "Accuracy:  0.984375, Loss:  0.196635439991951\n",
            "Accuracy:  0.984375, Loss:  0.35798683762550354\n",
            "Accuracy:  0.953125, Loss:  0.20986834168434143\n",
            "Accuracy:  0.875, Loss:  1.0881540775299072\n",
            "Accuracy:  0.953125, Loss:  0.47277864813804626\n",
            "Accuracy:  0.9375, Loss:  0.5899550318717957\n",
            "Accuracy:  0.90625, Loss:  0.7719376683235168\n",
            "Accuracy:  0.953125, Loss:  0.34739723801612854\n",
            "Accuracy:  0.921875, Loss:  0.6474543213844299\n",
            "Accuracy:  0.9375, Loss:  0.43482211232185364\n",
            "Accuracy:  0.890625, Loss:  0.917071521282196\n",
            "Accuracy:  0.984375, Loss:  0.28190141916275024\n",
            "Accuracy:  0.90625, Loss:  0.7796228528022766\n",
            "Accuracy:  0.9375, Loss:  0.5817028284072876\n",
            "Accuracy:  0.984375, Loss:  0.24807681143283844\n",
            "Accuracy:  0.9375, Loss:  0.5644986629486084\n",
            "Accuracy:  0.953125, Loss:  0.31391066312789917\n",
            "Accuracy:  0.984375, Loss:  0.3219117522239685\n",
            "Accuracy:  0.96875, Loss:  0.4690772294998169\n",
            "Accuracy:  0.953125, Loss:  0.3359331786632538\n",
            "Accuracy:  0.921875, Loss:  0.8141713738441467\n",
            "Accuracy:  0.9375, Loss:  0.49782201647758484\n",
            "Accuracy:  0.921875, Loss:  0.5282480120658875\n",
            "Accuracy:  0.96875, Loss:  0.19514816999435425\n",
            "Accuracy:  0.96875, Loss:  0.5000964999198914\n",
            "Accuracy:  0.953125, Loss:  0.6453286409378052\n",
            "Accuracy:  0.890625, Loss:  0.8404403924942017\n",
            "Accuracy:  0.921875, Loss:  0.5158578753471375\n",
            "Accuracy:  0.9375, Loss:  0.49506616592407227\n",
            "Accuracy:  0.90625, Loss:  0.9912168383598328\n",
            "Accuracy:  0.921875, Loss:  0.5337881445884705\n",
            "Accuracy:  0.953125, Loss:  0.7041867971420288\n",
            "Accuracy:  0.953125, Loss:  0.7341452240943909\n",
            "Accuracy:  1.0, Loss:  0.264029860496521\n",
            "Accuracy:  0.96875, Loss:  0.3919696807861328\n",
            "Accuracy:  0.90625, Loss:  0.6650834083557129\n",
            "Accuracy:  0.96875, Loss:  0.3534669280052185\n",
            "Accuracy:  0.953125, Loss:  0.40722939372062683\n",
            "Accuracy:  0.96875, Loss:  0.21177586913108826\n",
            "Accuracy:  0.96875, Loss:  0.20383408665657043\n",
            "Accuracy:  0.953125, Loss:  0.5271160006523132\n",
            "Accuracy:  0.953125, Loss:  0.4161745607852936\n",
            "Accuracy:  0.953125, Loss:  0.3344936966896057\n",
            "Accuracy:  0.96875, Loss:  0.7471553087234497\n",
            "Accuracy:  0.953125, Loss:  0.42431631684303284\n",
            "Accuracy:  0.84375, Loss:  0.734416127204895\n",
            "Accuracy:  0.953125, Loss:  0.4821336567401886\n",
            "Accuracy:  0.96875, Loss:  0.2264201045036316\n",
            "Accuracy:  0.953125, Loss:  0.5339666604995728\n",
            "Accuracy:  0.9375, Loss:  0.5519478917121887\n",
            "Accuracy:  0.96875, Loss:  0.3791474401950836\n",
            "Accuracy:  0.984375, Loss:  0.19633963704109192\n",
            "Accuracy:  0.96875, Loss:  0.1932488977909088\n",
            "Accuracy:  0.921875, Loss:  0.6650024652481079\n",
            "Accuracy:  0.9375, Loss:  0.7769898772239685\n",
            "Accuracy:  0.96875, Loss:  0.33846527338027954\n",
            "Accuracy:  0.875, Loss:  0.7853615880012512\n",
            "Accuracy:  0.96875, Loss:  0.3228268027305603\n",
            "Accuracy:  0.9375, Loss:  0.472975492477417\n",
            "Accuracy:  0.984375, Loss:  0.33277636766433716\n",
            "Accuracy:  0.96875, Loss:  0.40611883997917175\n",
            "Accuracy:  0.953125, Loss:  0.29526668787002563\n",
            "Accuracy:  0.9375, Loss:  0.33111441135406494\n",
            "Accuracy:  0.96875, Loss:  0.447991281747818\n",
            "Accuracy:  0.953125, Loss:  0.45444217324256897\n",
            "Accuracy:  0.9375, Loss:  0.39819473028182983\n",
            "Accuracy:  0.953125, Loss:  0.4289553761482239\n",
            "Accuracy:  0.9375, Loss:  0.41215598583221436\n",
            "Accuracy:  0.921875, Loss:  0.9173997044563293\n",
            "Accuracy:  0.90625, Loss:  0.4263902008533478\n",
            "Accuracy:  0.890625, Loss:  0.7941139340400696\n",
            "Accuracy:  0.96875, Loss:  0.26253804564476013\n",
            "Accuracy:  0.9375, Loss:  0.5952672958374023\n",
            "Accuracy:  0.96875, Loss:  0.4219388961791992\n",
            "Accuracy:  0.984375, Loss:  0.3624955117702484\n",
            "Accuracy:  0.953125, Loss:  0.222507506608963\n",
            "Accuracy:  0.984375, Loss:  0.3665173649787903\n",
            "Accuracy:  0.96875, Loss:  0.3085218369960785\n",
            "Accuracy:  0.96875, Loss:  0.42445024847984314\n",
            "Accuracy:  0.953125, Loss:  0.5317423343658447\n",
            "Accuracy:  0.9375, Loss:  0.8781387805938721\n",
            "Accuracy:  0.90625, Loss:  0.8042774200439453\n",
            "Accuracy:  0.984375, Loss:  0.44768229126930237\n",
            "Accuracy:  0.9375, Loss:  0.44122999906539917\n",
            "Accuracy:  0.90625, Loss:  0.8140980005264282\n",
            "Accuracy:  0.9375, Loss:  0.3741801381111145\n",
            "Accuracy:  0.96875, Loss:  0.39807361364364624\n",
            "Accuracy:  0.921875, Loss:  0.5741311311721802\n",
            "Accuracy:  0.9375, Loss:  0.6512722969055176\n",
            "Accuracy:  0.953125, Loss:  0.34102100133895874\n",
            "Accuracy:  0.90625, Loss:  0.4850037097930908\n",
            "Accuracy:  1.0, Loss:  0.17921358346939087\n",
            "Accuracy:  0.96875, Loss:  0.24631910026073456\n",
            "Accuracy:  0.953125, Loss:  0.6698058843612671\n",
            "Accuracy:  0.96875, Loss:  0.26896747946739197\n",
            "Accuracy:  0.953125, Loss:  0.4963182806968689\n",
            "Accuracy:  0.96875, Loss:  0.450679749250412\n",
            "Accuracy:  0.90625, Loss:  0.7334194779396057\n",
            "Accuracy:  0.859375, Loss:  0.6971642971038818\n",
            "Accuracy:  0.984375, Loss:  0.2104511857032776\n",
            "Accuracy:  0.890625, Loss:  0.6877748370170593\n",
            "Accuracy:  0.9375, Loss:  0.655605137348175\n",
            "Accuracy:  0.90625, Loss:  0.6983354091644287\n",
            "Accuracy:  1.0, Loss:  0.20460760593414307\n",
            "Accuracy:  0.953125, Loss:  0.5024614334106445\n",
            "Accuracy:  0.921875, Loss:  0.5360600352287292\n",
            "Accuracy:  0.9375, Loss:  0.4648562967777252\n",
            "Accuracy:  0.96875, Loss:  0.416593998670578\n",
            "Accuracy:  0.921875, Loss:  0.9790961742401123\n",
            "Accuracy:  0.96875, Loss:  0.362151175737381\n",
            "Accuracy:  0.953125, Loss:  0.6519560217857361\n",
            "Accuracy:  0.953125, Loss:  0.48877575993537903\n",
            "Accuracy:  0.890625, Loss:  0.6534234285354614\n",
            "Accuracy:  0.984375, Loss:  0.45199257135391235\n",
            "Accuracy:  0.96875, Loss:  0.4234488010406494\n",
            "Accuracy:  0.96875, Loss:  0.4819331169128418\n",
            "Accuracy:  0.9375, Loss:  0.7049077153205872\n",
            "Accuracy:  0.984375, Loss:  0.3380412459373474\n",
            "Accuracy:  0.984375, Loss:  0.22571104764938354\n",
            "Accuracy:  0.9375, Loss:  0.3691219687461853\n",
            "Accuracy:  0.90625, Loss:  0.41923651099205017\n",
            "Accuracy:  0.921875, Loss:  0.5705804824829102\n",
            "Accuracy:  0.984375, Loss:  0.38217177987098694\n",
            "Accuracy:  0.890625, Loss:  0.7932151556015015\n",
            "Accuracy:  0.96875, Loss:  0.451981782913208\n",
            "Accuracy:  0.96875, Loss:  0.381891131401062\n",
            "Accuracy:  0.953125, Loss:  0.40796029567718506\n",
            "Accuracy:  0.953125, Loss:  0.34634193778038025\n",
            "Accuracy:  0.890625, Loss:  0.9449537396430969\n",
            "Accuracy:  0.890625, Loss:  0.692780613899231\n",
            "Accuracy:  0.96875, Loss:  0.36934593319892883\n",
            "Accuracy:  0.921875, Loss:  0.9098978042602539\n",
            "Accuracy:  0.9375, Loss:  0.5906800627708435\n",
            "Accuracy:  0.921875, Loss:  0.5990225076675415\n",
            "Accuracy:  0.921875, Loss:  0.4825924336910248\n",
            "Accuracy:  0.90625, Loss:  0.6354265213012695\n",
            "Accuracy:  0.953125, Loss:  0.2506757974624634\n",
            "Accuracy:  0.9375, Loss:  0.5346683859825134\n",
            "Accuracy:  0.984375, Loss:  0.22478057444095612\n",
            "Accuracy:  0.9375, Loss:  0.659735381603241\n",
            "Accuracy:  0.90625, Loss:  0.5718863010406494\n",
            "Accuracy:  0.9375, Loss:  0.4119907319545746\n",
            "Accuracy:  0.984375, Loss:  0.2947518825531006\n",
            "Accuracy:  0.984375, Loss:  0.3159976303577423\n",
            "Accuracy:  0.96875, Loss:  0.27697402238845825\n",
            "Accuracy:  0.953125, Loss:  0.3047689199447632\n",
            "Accuracy:  0.9375, Loss:  0.5791434049606323\n",
            "Accuracy:  0.90625, Loss:  0.861763596534729\n",
            "Accuracy:  0.890625, Loss:  0.8634277582168579\n",
            "Accuracy:  0.953125, Loss:  0.670010507106781\n",
            "Accuracy:  0.96875, Loss:  0.24586229026317596\n",
            "Accuracy:  0.9375, Loss:  0.7885136008262634\n",
            "Accuracy:  0.984375, Loss:  0.2200840711593628\n",
            "Accuracy:  0.9375, Loss:  0.6782630085945129\n",
            "Accuracy:  0.984375, Loss:  0.30288276076316833\n",
            "Accuracy:  0.921875, Loss:  0.45087236166000366\n",
            "Accuracy:  0.859375, Loss:  0.8892974853515625\n",
            "Accuracy:  0.953125, Loss:  0.5473117828369141\n",
            "Accuracy:  0.953125, Loss:  0.43050816655158997\n",
            "Accuracy:  0.984375, Loss:  0.39331936836242676\n",
            "Accuracy:  0.953125, Loss:  0.43396174907684326\n",
            "Accuracy:  0.984375, Loss:  0.25428199768066406\n",
            "Accuracy:  0.96875, Loss:  0.6263116002082825\n",
            "Accuracy:  0.921875, Loss:  0.4670782685279846\n",
            "Accuracy:  0.984375, Loss:  0.4900425970554352\n",
            "Accuracy:  0.953125, Loss:  0.4131815433502197\n",
            "Accuracy:  0.890625, Loss:  0.734847366809845\n",
            "Accuracy:  0.921875, Loss:  0.7759336233139038\n",
            "Accuracy:  0.9375, Loss:  1.1000843048095703\n",
            "Accuracy:  0.9375, Loss:  1.0499858856201172\n",
            "Accuracy:  0.9375, Loss:  0.7078725695610046\n",
            "Accuracy:  0.984375, Loss:  0.5547389984130859\n",
            "Accuracy:  0.984375, Loss:  0.32114744186401367\n",
            "Accuracy:  0.9375, Loss:  0.6537058353424072\n",
            "Accuracy:  0.96875, Loss:  0.5376265645027161\n",
            "Accuracy:  0.9375, Loss:  0.5306404829025269\n",
            "Accuracy:  0.921875, Loss:  0.5042386651039124\n",
            "Accuracy:  0.96875, Loss:  0.4377276599407196\n",
            "Accuracy:  0.875, Loss:  0.6062431335449219\n",
            "Accuracy:  0.921875, Loss:  0.5363328456878662\n",
            "Accuracy:  0.921875, Loss:  1.025587797164917\n",
            "Accuracy:  0.953125, Loss:  0.4258647859096527\n",
            "Accuracy:  0.953125, Loss:  0.5245299339294434\n",
            "Accuracy:  0.90625, Loss:  0.8175680041313171\n",
            "Accuracy:  0.921875, Loss:  0.7311256527900696\n",
            "Accuracy:  0.953125, Loss:  0.5554507374763489\n",
            "Accuracy:  0.9375, Loss:  0.3868538439273834\n",
            "Accuracy:  0.96875, Loss:  0.4951639175415039\n",
            "Accuracy:  0.9375, Loss:  0.31114670634269714\n",
            "Accuracy:  0.984375, Loss:  0.3332695960998535\n",
            "Accuracy:  0.9375, Loss:  0.4153744876384735\n",
            "Accuracy:  0.9375, Loss:  0.504364550113678\n",
            "Accuracy:  0.96875, Loss:  0.27454283833503723\n",
            "Accuracy:  0.984375, Loss:  0.3485071361064911\n",
            "Accuracy:  0.96875, Loss:  0.558495044708252\n",
            "Accuracy:  0.90625, Loss:  0.9574057459831238\n",
            "Accuracy:  0.9375, Loss:  0.4050889313220978\n",
            "Accuracy:  0.90625, Loss:  0.6888910531997681\n",
            "Accuracy:  0.984375, Loss:  0.3170269727706909\n",
            "Accuracy:  0.9375, Loss:  0.6299138069152832\n",
            "Accuracy:  0.953125, Loss:  0.3673992156982422\n",
            "Accuracy:  0.921875, Loss:  0.6258422136306763\n",
            "Accuracy:  1.0, Loss:  0.24837318062782288\n",
            "Accuracy:  0.9375, Loss:  0.7664921283721924\n",
            "Accuracy:  0.90625, Loss:  0.746405839920044\n",
            "Accuracy:  0.953125, Loss:  0.33886057138442993\n",
            "Accuracy:  0.921875, Loss:  0.5507856607437134\n",
            "Accuracy:  0.96875, Loss:  0.3035614788532257\n",
            "Accuracy:  0.96875, Loss:  0.35970914363861084\n",
            "Accuracy:  0.953125, Loss:  0.28493890166282654\n",
            "Accuracy:  0.984375, Loss:  0.2672489285469055\n",
            "Accuracy:  0.921875, Loss:  0.8065578937530518\n",
            "Accuracy:  0.984375, Loss:  0.3950059115886688\n",
            "Accuracy:  0.984375, Loss:  0.32160666584968567\n",
            "Accuracy:  0.890625, Loss:  0.8346396684646606\n",
            "Accuracy:  0.96875, Loss:  0.5919774770736694\n",
            "Accuracy:  0.96875, Loss:  0.41082972288131714\n",
            "Accuracy:  0.96875, Loss:  0.3680694103240967\n",
            "Accuracy:  0.9375, Loss:  0.755506157875061\n",
            "Accuracy:  0.953125, Loss:  0.36447644233703613\n",
            "Accuracy:  0.984375, Loss:  0.22365781664848328\n",
            "Accuracy:  0.96875, Loss:  0.3906552493572235\n",
            "Accuracy:  0.90625, Loss:  0.7641857862472534\n",
            "Accuracy:  0.984375, Loss:  0.39310985803604126\n",
            "Accuracy:  0.96875, Loss:  0.250288724899292\n",
            "Accuracy:  0.890625, Loss:  0.776536226272583\n",
            "Accuracy:  0.859375, Loss:  0.8529276847839355\n",
            "Accuracy:  0.921875, Loss:  0.5029923915863037\n",
            "Accuracy:  0.984375, Loss:  0.1624760925769806\n",
            "Accuracy:  0.953125, Loss:  0.6810562610626221\n",
            "Accuracy:  0.953125, Loss:  0.3484079837799072\n",
            "Accuracy:  0.921875, Loss:  1.1949787139892578\n",
            "Accuracy:  0.96875, Loss:  0.3700752854347229\n",
            "Accuracy:  0.890625, Loss:  0.6151459217071533\n",
            "Accuracy:  0.953125, Loss:  0.550693929195404\n",
            "Accuracy:  0.96875, Loss:  0.36043596267700195\n",
            "Accuracy:  0.921875, Loss:  0.7000560164451599\n",
            "Accuracy:  0.9375, Loss:  0.5486751198768616\n",
            "Accuracy:  0.9375, Loss:  0.5611676573753357\n",
            "Accuracy:  0.984375, Loss:  0.1838788539171219\n",
            "Accuracy:  0.921875, Loss:  0.47498658299446106\n",
            "Accuracy:  0.96875, Loss:  0.3589963912963867\n",
            "Accuracy:  0.984375, Loss:  0.32341474294662476\n",
            "Accuracy:  0.9375, Loss:  0.9681143760681152\n",
            "Accuracy:  0.90625, Loss:  0.5050253868103027\n",
            "Accuracy:  0.96875, Loss:  0.2766322195529938\n",
            "Accuracy:  0.921875, Loss:  0.5198268294334412\n",
            "Accuracy:  0.953125, Loss:  0.9552228450775146\n",
            "Accuracy:  0.9375, Loss:  0.4698255658149719\n",
            "Accuracy:  0.9375, Loss:  0.4081886410713196\n",
            "Accuracy:  0.953125, Loss:  0.6085599064826965\n",
            "Accuracy:  0.90625, Loss:  0.6477296948432922\n",
            "Accuracy:  0.953125, Loss:  0.540124773979187\n",
            "Accuracy:  0.96875, Loss:  0.53859943151474\n",
            "Accuracy:  0.9375, Loss:  1.015036940574646\n",
            "Accuracy:  0.875, Loss:  0.8906187415122986\n",
            "Accuracy:  0.984375, Loss:  0.33432501554489136\n",
            "Accuracy:  0.921875, Loss:  0.4048185646533966\n",
            "Accuracy:  0.90625, Loss:  0.48774415254592896\n",
            "Accuracy:  0.984375, Loss:  0.2271275818347931\n",
            "Accuracy:  0.96875, Loss:  0.27723801136016846\n",
            "Accuracy:  0.96875, Loss:  0.41682183742523193\n",
            "Accuracy:  0.90625, Loss:  0.8780437111854553\n",
            "Accuracy:  0.953125, Loss:  0.517926037311554\n",
            "Accuracy:  0.96875, Loss:  0.47262001037597656\n",
            "Accuracy:  0.921875, Loss:  0.8061805367469788\n",
            "Accuracy:  0.953125, Loss:  0.9189833402633667\n",
            "Accuracy:  0.9375, Loss:  0.4223887026309967\n",
            "Accuracy:  0.953125, Loss:  0.5138470530509949\n",
            "Accuracy:  0.953125, Loss:  0.5288001298904419\n",
            "Accuracy:  0.921875, Loss:  0.8936225771903992\n",
            "Accuracy:  0.984375, Loss:  0.5452653169631958\n",
            "Accuracy:  0.96875, Loss:  0.41463902592658997\n",
            "Accuracy:  0.953125, Loss:  0.8147761225700378\n",
            "Accuracy:  0.96875, Loss:  0.4728451669216156\n",
            "Accuracy:  1.0, Loss:  0.26450076699256897\n",
            "Accuracy:  0.875, Loss:  0.8060990571975708\n",
            "Accuracy:  0.984375, Loss:  0.17669765651226044\n",
            "Accuracy:  0.96875, Loss:  0.28461670875549316\n",
            "Accuracy:  0.921875, Loss:  0.6566035151481628\n",
            "Accuracy:  0.9375, Loss:  0.48133963346481323\n",
            "Accuracy:  0.96875, Loss:  0.23140212893486023\n",
            "Accuracy:  0.921875, Loss:  0.6027889251708984\n",
            "Accuracy:  0.96875, Loss:  0.3648548424243927\n",
            "Accuracy:  0.953125, Loss:  0.3739287257194519\n",
            "Accuracy:  0.984375, Loss:  0.2662087678909302\n",
            "Accuracy:  0.921875, Loss:  0.6462041735649109\n",
            "Accuracy:  0.921875, Loss:  0.7097736597061157\n",
            "Accuracy:  0.921875, Loss:  0.6549198031425476\n",
            "Accuracy:  0.96875, Loss:  0.4051392376422882\n",
            "Accuracy:  0.953125, Loss:  0.2794397175312042\n",
            "Accuracy:  0.890625, Loss:  0.859046459197998\n",
            "Accuracy:  0.9375, Loss:  0.66848224401474\n",
            "Accuracy:  0.9375, Loss:  0.4099276661872864\n",
            "Accuracy:  0.984375, Loss:  0.18341855704784393\n",
            "Accuracy:  0.96875, Loss:  0.35316216945648193\n",
            "Accuracy:  0.96875, Loss:  0.2907083332538605\n",
            "Accuracy:  0.921875, Loss:  0.42951375246047974\n",
            "Accuracy:  0.90625, Loss:  0.6471519470214844\n",
            "Accuracy:  0.96875, Loss:  0.351365327835083\n",
            "Accuracy:  0.90625, Loss:  0.8971680402755737\n",
            "Accuracy:  0.96875, Loss:  0.2109816074371338\n",
            "Accuracy:  0.953125, Loss:  0.44945889711380005\n",
            "Accuracy:  0.9375, Loss:  0.45374196767807007\n",
            "Accuracy:  0.921875, Loss:  0.34734493494033813\n",
            "Accuracy:  0.96875, Loss:  0.22576099634170532\n",
            "Accuracy:  0.9375, Loss:  0.41775158047676086\n",
            "Accuracy:  0.9375, Loss:  0.6757882833480835\n",
            "Accuracy:  0.9375, Loss:  0.38458287715911865\n",
            "Accuracy:  0.9375, Loss:  0.6171901226043701\n",
            "Accuracy:  0.921875, Loss:  0.7501922845840454\n",
            "Accuracy:  0.9375, Loss:  0.6284886598587036\n",
            "Accuracy:  0.875, Loss:  0.8237879276275635\n",
            "Accuracy:  0.9375, Loss:  0.35211414098739624\n",
            "Accuracy:  0.984375, Loss:  0.4135403037071228\n",
            "Accuracy:  0.953125, Loss:  0.36969512701034546\n",
            "Accuracy:  0.984375, Loss:  0.15537217259407043\n",
            "Accuracy:  0.921875, Loss:  0.893214225769043\n",
            "Accuracy:  0.9375, Loss:  0.6122485995292664\n",
            "Accuracy:  0.890625, Loss:  0.8588635921478271\n",
            "Accuracy:  0.921875, Loss:  1.216351866722107\n",
            "Accuracy:  0.921875, Loss:  0.4400129020214081\n",
            "Accuracy:  0.984375, Loss:  0.4457858204841614\n",
            "Accuracy:  0.90625, Loss:  0.9276823401451111\n",
            "Accuracy:  0.9375, Loss:  0.7379668951034546\n",
            "Accuracy:  0.984375, Loss:  0.2737877666950226\n",
            "Accuracy:  0.953125, Loss:  0.5358940362930298\n",
            "Accuracy:  0.96875, Loss:  0.47030380368232727\n",
            "Accuracy:  0.9375, Loss:  0.8156563639640808\n",
            "Accuracy:  1.0, Loss:  0.19790434837341309\n",
            "Accuracy:  0.953125, Loss:  0.3240165412425995\n",
            "Accuracy:  0.96875, Loss:  0.4556204378604889\n",
            "Accuracy:  0.9375, Loss:  0.9102852940559387\n",
            "Accuracy:  0.96875, Loss:  0.33298927545547485\n",
            "Accuracy:  0.9375, Loss:  0.5733658671379089\n",
            "Accuracy:  0.9375, Loss:  0.549433708190918\n",
            "Accuracy:  0.90625, Loss:  0.5431156754493713\n",
            "Accuracy:  0.953125, Loss:  0.332186222076416\n",
            "Accuracy:  0.96875, Loss:  0.3181826174259186\n",
            "Accuracy:  0.953125, Loss:  0.8475719094276428\n",
            "Accuracy:  0.953125, Loss:  0.3325028717517853\n",
            "Accuracy:  0.921875, Loss:  0.7792997360229492\n",
            "Accuracy:  0.984375, Loss:  0.26682350039482117\n",
            "Accuracy:  0.9375, Loss:  0.5091851353645325\n",
            "Accuracy:  0.90625, Loss:  0.9788926243782043\n",
            "Accuracy:  0.96875, Loss:  0.42600348591804504\n",
            "Accuracy:  0.984375, Loss:  0.2979130446910858\n",
            "Accuracy:  0.90625, Loss:  0.8978723883628845\n",
            "Accuracy:  0.96875, Loss:  0.1765138804912567\n",
            "Accuracy:  0.90625, Loss:  0.5225986838340759\n",
            "Accuracy:  0.953125, Loss:  0.5326082706451416\n",
            "Accuracy:  0.921875, Loss:  0.8554126620292664\n",
            "Accuracy:  0.953125, Loss:  0.30131494998931885\n",
            "Accuracy:  0.953125, Loss:  0.32851117849349976\n",
            "Accuracy:  0.984375, Loss:  0.18790769577026367\n",
            "Accuracy:  0.9375, Loss:  0.5231943726539612\n",
            "Accuracy:  0.9375, Loss:  0.6031082272529602\n",
            "Accuracy:  0.953125, Loss:  0.7216828465461731\n",
            "Accuracy:  0.9375, Loss:  0.735515832901001\n",
            "Accuracy:  1.0, Loss:  0.16148322820663452\n",
            "Accuracy:  0.9375, Loss:  0.35899513959884644\n",
            "Accuracy:  0.921875, Loss:  0.7223930358886719\n",
            "Accuracy:  1.0, Loss:  0.25165045261383057\n",
            "Accuracy:  0.984375, Loss:  0.45029059052467346\n",
            "Accuracy:  1.0, Loss:  0.2590569257736206\n",
            "Accuracy:  0.96875, Loss:  0.24519428610801697\n",
            "Accuracy:  0.953125, Loss:  0.5956830382347107\n",
            "Accuracy:  0.9375, Loss:  0.6183564066886902\n",
            "Accuracy:  0.984375, "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-a67dac76c39b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# loss_root.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VA8s6lSBRuH_",
        "outputId": "5e4db36a-07f4-4e16-bc7d-61a6a0f56cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "with open('model.pth', 'wb') as f:\n",
        "  torch.save(model, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GraphemeModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Bottleneck. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p1HTkFc7Ox4b",
        "colab": {}
      },
      "source": [
        "class TestDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, test_images, image_ids, transforms=None):\n",
        "        super(TestDataset, self).__init__()\n",
        "        self.image_ids = image_ids\n",
        "        self.test_images = test_images\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_id = self.image_ids.iloc[index]\n",
        "        img_array = np.zeros((137, 236, 3), dtype='uint8')\n",
        "        img_array[:, :, 0] = self.test_images[index].reshape(137, 236)\n",
        "        img_array[:, :, 1] = img_array[:, :, 0]\n",
        "        img_array[:, :, 2] = img_array[:, :, 0]\n",
        "        img = Image.fromarray(img_array)\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __len__(self,):\n",
        "        return len(self.image_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ABBgJVOfKFmw",
        "colab": {}
      },
      "source": [
        "test_image_data_0 = pd.read_parquet('test_image_data_0.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NzHB0XXjKzqk",
        "colab": {}
      },
      "source": [
        "test_image_data_1 = pd.read_parquet('test_image_data_1.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ygzvPMmtKLjJ",
        "colab": {}
      },
      "source": [
        "test_image_data_2 = pd.read_parquet('test_image_data_2.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M8BtgSo7K3VH",
        "colab": {}
      },
      "source": [
        "test_image_data_3 = pd.read_parquet('test_image_data_3.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qgn4zfK_KruZ",
        "outputId": "8534b311-1e58-4207-d98b-00ecc265a284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_image_data_0.shape, test_image_data_1.shape, test_image_data_2.shape, test_image_data_3.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3, 32333), (3, 32333), (3, 32333), (3, 32333))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4_VQdhQ0Ju4s",
        "colab": {}
      },
      "source": [
        "test_matrix = np.concatenate([\n",
        "                              test_image_data_0.drop(columns=['image_id']).values,\n",
        "                              test_image_data_1.drop(columns=['image_id']).values,\n",
        "                              test_image_data_2.drop(columns=['image_id']).values,\n",
        "                              test_image_data_3.drop(columns=['image_id']).values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lzw3Xx2FLkZg",
        "outputId": "7148997f-1bfa-45f9-aefe-9af2eeb7102f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 32332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hE7P3bjuLQv2",
        "colab": {}
      },
      "source": [
        "image_ids = test_image_data_0.image_id.append(test_image_data_1.image_id).append(test_image_data_2.image_id).append(test_image_data_3.image_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m5dvgu1fJgd_",
        "colab": {}
      },
      "source": [
        "test_dataset = TestDataset(test_images=test_matrix, image_ids=image_ids, transforms=transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1nl2aAPdJgqi",
        "colab": {}
      },
      "source": [
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1024, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TM5T-uFXKcBq",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "for x in test_dataloader:\n",
        "  output = model(x.to(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UwL8IcEDmOo7",
        "colab": {}
      },
      "source": [
        "output"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}